# Since .env is gitignored, you can use .env.example to build a new `.env` file when you clone the repo.
# Keep this file up-to-date when you add new variables to \`.env\`.

# This file will be committed to version control, so make sure not to have any secrets in it.
# If you are cloning this repo, create a copy of this file named `.env` and populate it with your secrets.

# The database URL is used to connect to your PostgreSQL database.
# For k3s cluster use internal service name: postgresql://user:password@postgres-service:5432/dbname
# For local development: postgresql://postgres:postgres@localhost:5432/selectio
POSTGRES_URL="postgresql://postgres:postgres@localhost:5432/selectio"


# You can generate the secret via 'openssl rand -base64 32' on Unix
# @see https://www.better-auth.com/docs/installation
AUTH_SECRET='supersecret'

# Preconfigured GOOGLE OAuth provider, works out-of-the-box
# @see https://www.better-auth.com/docs/authentication/google
AUTH_GOOGLE_ID=''
AUTH_GOOGLE_SECRET=''

# Encryption key for storing sensitive data (integrations credentials)
# Generate via: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
ENCRYPTION_KEY=''

# AI Provider Configuration
# Choose between 'openai' or 'deepseek' (default: openai)
# If primary provider key is missing, automatically falls back to the other
AI_PROVIDER='openai'

# AI Model (optional, uses defaults if not specified)
# For OpenAI: gpt-4o-mini (default), gpt-4o, gpt-4-turbo
# For DeepSeek: deepseek-chat (default), deepseek-coder
AI_MODEL=''

# OpenAI API key (primary for interviews, also used for Whisper transcription)
# Get your API key from https://platform.openai.com
OPENAI_API_KEY=''

# DeepSeek API key (fallback if OpenAI key is missing)
# Get your API key from https://platform.deepseek.com
DEEPSEEK_API_KEY=''

# Langfuse observability for AI SDK
# Get your keys from https://cloud.langfuse.com
LANGFUSE_SECRET_KEY=''
LANGFUSE_PUBLIC_KEY=''
LANGFUSE_BASE_URL='https://cloud.langfuse.com'

# Telegram Bot Token
# Get your token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=''

# Telegram Bot Username (without @)
# Used for generating invite links
TELEGRAM_BOT_USERNAME=''

# Telegram API credentials for MTCute (sending messages by username)
# Get from https://my.telegram.org/apps
TELEGRAM_API_ID=''
TELEGRAM_API_HASH=''

# AWS S3 / MinIO Configuration
AWS_S3_ENDPOINT='http://localhost:9000'
AWS_S3_BUCKET='selectio'
AWS_REGION='us-east-1'
AWS_ACCESS_KEY_ID='minioadmin'
AWS_SECRET_ACCESS_KEY='minioadmin'
AWS_S3_FORCE_PATH_STYLE='true'

# Application URL (used for OAuth callbacks, workspace URLs and emails)
# ВАЖНО: В продакшене должен быть публичный URL, а не внутренний адрес контейнера
# Например: https://yourdomain.com
APP_URL='http://localhost:3000'

# AI Proxy URL (used for OpenAI API proxying, including Whisper transcription)
# If not set, falls back to APP_URL
AI_PROXY_URL='http://localhost:3000'

# Public URLs for web landing page
NEXT_PUBLIC_APP_URL='http://localhost:3000'
NEXT_PUBLIC_APP_NAME='QBS Автонайм'

# Interview Buffer Configuration
# Debounce timeout (seconds) - время ожидания после последнего сообщения перед обработкой
# Рекомендуется 15-20 секунд для баланса между скоростью ответа и группировкой сообщений
# Учитывает время транскрибации голосовых (5-15 сек)
INTERVIEW_BUFFER_DEBOUNCE_TIMEOUT=15
# Typing activity timeout (seconds) - время ожидания после активности печати
INTERVIEW_TYPING_DEBOUNCE_TIMEOUT=30
# Enable/disable message buffering
INTERVIEW_BUFFER_ENABLED=true

# Qdrant Vector Database Configuration
# URL for Qdrant service
QDRANT_URL='http://localhost:6333'
# Optional API key for Qdrant (leave empty for local Docker)
QDRANT_API_KEY=''
# Collection name for document embeddings
QDRANT_COLLECTION_NAME='document_embeddings'

# Docling Document Processing Configuration
# URL for Docling service
DOCLING_API_URL='http://localhost:8000'
# Optional API key for Docling (leave empty for local Docker)
DOCLING_API_KEY=''



