import { messageBufferService } from "../../../services/buffer";
import {
  analyzeAndGenerateNextQuestion,
  getInterviewContext,
} from "../../../services/interview";
import { inngest } from "../../client";

/**
 * Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ flush Ð±ÑƒÑ„ÐµÑ€Ð°
 * ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð² LLM
 * Ð˜Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð°Ñ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ñ
 *
 * Requirements: 4.1, 4.2, 4.3, 4.4, 5.1, 5.2, 5.3
 */
export const bufferFlushFunction = inngest.createFunction(
  {
    id: "interview-buffer-flush",
    name: "Interview Buffer Flush",
    idempotency: "event.data.flushId",
    retries: 3,
  },
  { event: "interview/buffer.flush" },
  async ({ event, step }) => {
    const { userId, conversationId, interviewStep, flushId } = event.data;

    console.log("ðŸš€ Buffer flush started", {
      userId,
      conversationId,
      interviewStep,
      flushId,
    });

    // ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸Ð· Ð±ÑƒÑ„ÐµÑ€Ð°
    const messages = await step.run("get-buffered-messages", async () => {
      const bufferedMessages = await messageBufferService.getMessages({
        userId,
        conversationId,
        interviewStep,
      });

      console.log("ðŸ“¦ Retrieved buffered messages", {
        userId,
        conversationId,
        interviewStep,
        messageCount: bufferedMessages.length,
      });

      return bufferedMessages;
    });

    // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿ÑƒÑÑ‚Ð¾Ð³Ð¾ Ð±ÑƒÑ„ÐµÑ€Ð°
    if (messages.length === 0) {
      console.log("âš ï¸ Buffer is empty, skipping flush", {
        userId,
        conversationId,
        interviewStep,
        flushId,
      });
      return { skipped: true, reason: "Buffer is empty" };
    }

    // ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
    const aggregatedContent = await step.run("aggregate-messages", async () => {
      const content = messages.map((m) => m.content).join("\n\n");

      console.log("ðŸ“ Messages aggregated", {
        userId,
        conversationId,
        interviewStep,
        messageCount: messages.length,
        totalLength: content.length,
      });

      return content;
    });

    // ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°
    const currentQuestion = messages[0]?.questionContext || "";

    // ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ
    const context = await step.run("get-interview-context", async () => {
      console.log("ðŸ“‹ Getting interview context", {
        conversationId,
        currentQuestion,
      });

      const ctx = await getInterviewContext(
        conversationId,
        aggregatedContent,
        currentQuestion,
      );

      if (!ctx) {
        throw new Error("Interview context not found");
      }

      return ctx;
    });

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð² LLM
    const llmResponse = await step.run("send-to-llm", async () => {
      console.log("ðŸ¤– Sending to LLM", {
        conversationId,
        questionNumber: context.questionNumber,
        messageCount: messages.length,
      });

      try {
        const result = await analyzeAndGenerateNextQuestion(context);

        console.log("ðŸ“Š LLM response received", {
          conversationId,
          shouldContinue: result.shouldContinue,
          hasQuestion: !!result.nextQuestion,
          reason: result.reason,
        });

        return { success: true, data: result };
      } catch (error) {
        const errorMessage =
          error instanceof Error ? error.message : String(error);

        // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÑ‚Ð¾ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹ API (Bad Request Ð¸ Ñ‚.Ð´.)
        const isAPIError =
          errorMessage.includes("Bad Request") ||
          errorMessage.includes("API") ||
          errorMessage.includes("AI_APICallError");

        console.error("âŒ LLM request failed", {
          conversationId,
          error: errorMessage,
          isAPIError,
          stack: error instanceof Error ? error.stack : undefined,
        });

        return {
          success: false,
          error: errorMessage,
          isAPIError,
        };
      }
    });

    // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº LLM
    if (!llmResponse.success) {
      console.error("âŒ Skipping response due to LLM error", {
        conversationId,
        error: llmResponse.error,
        isAPIError: llmResponse.isAPIError,
      });

      // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð±ÑƒÑ„ÐµÑ€ Ð´Ð°Ð¶Ðµ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
      await step.run("clear-buffer-on-error", async () => {
        await messageBufferService.clearBuffer({
          userId,
          conversationId,
          interviewStep,
        });

        console.log("ðŸ§¹ Buffer cleared after error", {
          userId,
          conversationId,
          interviewStep,
        });

        return { cleared: true };
      });

      return {
        success: false,
        error: llmResponse.error,
        messageCount: messages.length,
        flushId,
        skippedResponse: true,
      };
    }

    const result = llmResponse.data;

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾Ñ‚Ð²ÐµÑ‚Ð° ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñƒ
    await step.run("send-response", async () => {
      if (result.shouldContinue && result.nextQuestion) {
        // ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ„Ð»Ð¾Ñƒ: Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ Ñ Ð½Ð¾Ð²Ñ‹Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼
        console.log("âž¡ï¸ Sending next question", {
          conversationId,
          questionNumber: context.questionNumber,
        });

        await inngest.send({
          name: "telegram/interview.send-question",
          data: {
            conversationId: context.conversationId,
            question: result.nextQuestion,
            transcription: aggregatedContent,
            questionNumber: context.questionNumber,
          },
        });
      } else if (
        result.nextQuestion &&
        result.nextQuestion !== "[SKIP]" &&
        result.nextQuestion.trim().length > 0
      ) {
        // Ð•ÑÑ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñƒ, Ð½Ð¾ shouldContinue=false
        console.log("ðŸ’¬ Sending response without continuing", {
          conversationId,
          reason: result.reason,
        });

        await inngest.send({
          name: "telegram/interview.send-question",
          data: {
            conversationId: context.conversationId,
            question: result.nextQuestion,
            transcription: aggregatedContent,
            questionNumber: context.questionNumber,
          },
        });
      } else {
        // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ
        const isSimpleAcknowledgment = result.isSimpleAcknowledgment === true;

        if (isSimpleAcknowledgment) {
          console.log("â¸ï¸ Simple acknowledgment, not completing interview", {
            conversationId,
            reason: result.reason,
          });
        } else {
          // Ð—Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ
          console.log("ðŸ Completing interview", {
            conversationId,
            reason: result.reason,
          });

          await inngest.send({
            name: "telegram/interview.complete",
            data: {
              conversationId: context.conversationId,
              transcription: aggregatedContent,
              reason: result.reason ?? undefined,
              questionNumber: context.questionNumber,
              responseId: context.responseId ?? undefined,
            },
          });
        }
      }

      return {
        sent: true,
        shouldContinue: result.shouldContinue,
      };
    });

    // ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð±ÑƒÑ„ÐµÑ€Ð°
    await step.run("clear-buffer", async () => {
      await messageBufferService.clearBuffer({
        userId,
        conversationId,
        interviewStep,
      });

      console.log("ðŸ§¹ Buffer cleared", {
        userId,
        conversationId,
        interviewStep,
      });

      return { cleared: true };
    });

    console.log("âœ… Buffer flush completed", {
      userId,
      conversationId,
      interviewStep,
      flushId,
      messageCount: messages.length,
    });

    return {
      success: true,
      messageCount: messages.length,
      flushId,
      shouldContinue: llmResponse.shouldContinue,
    };
  },
);
